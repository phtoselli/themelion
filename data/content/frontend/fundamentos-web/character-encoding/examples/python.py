# ==============================================================
# CodificaÃ§Ã£o de Caracteres em Python
# ==============================================================
# Python 3 usa Unicode internamente para todas as strings (str).
# bytes Ã© o tipo para dados binÃ¡rios/codificados.

# --- Strings sÃ£o Unicode, bytes sÃ£o codificados ---

texto = "OlÃ¡, SÃ£o Paulo!"

# str â†’ bytes: encode() transforma Unicode em sequÃªncia de bytes
utf8_bytes = texto.encode("utf-8")
print(utf8_bytes)
# b'Ol\xc3\xa1, S\xc3\xa3o Paulo!'
# 'Ã¡' = 2 bytes (0xC3, 0xA1), 'Ã£' = 2 bytes (0xC3, 0xA3)

print(f"Caracteres: {len(texto)}")      # 15 caracteres
print(f"Bytes UTF-8: {len(utf8_bytes)}") # 17 bytes (2 extras para Ã¡ e Ã£)

# bytes â†’ str: decode() reconstrÃ³i a string Unicode
texto_de_volta = utf8_bytes.decode("utf-8")
print(texto_de_volta)  # "OlÃ¡, SÃ£o Paulo!"


# --- Comparando encodings ---

texto = "ProgramaÃ§Ã£o"

utf8 = texto.encode("utf-8")
latin1 = texto.encode("latin-1")
utf16 = texto.encode("utf-16")

print(f"UTF-8:   {len(utf8)} bytes  â†’ {list(utf8)}")
# UTF-8:   13 bytes  â†’ [80, 114, 111, 103, 114, 97, 109, 97, 195, 167, 195, 163, 111]
# Ã§ = [195, 167], Ã£ = [195, 163] â€” 2 bytes cada

print(f"Latin-1: {len(latin1)} bytes â†’ {list(latin1)}")
# Latin-1: 11 bytes â†’ [80, 114, 111, 103, 114, 97, 109, 97, 231, 227, 111]
# Ã§ = [231], Ã£ = [227] â€” 1 byte cada (mais compacto, mas limitado)

print(f"UTF-16:  {len(utf16)} bytes â†’ {list(utf16)}")
# UTF-16:  24 bytes â†’ [255, 254, 80, 0, 114, 0, ...] â€” 2 bytes por caractere + BOM


# --- Mojibake: o que acontece com encoding errado ---

original = "SÃ£o Paulo"
bytes_utf8 = original.encode("utf-8")

# Decodificar UTF-8 com Latin-1 â†’ mojibake!
errado = bytes_utf8.decode("latin-1")
print(f"Correto: {original}")
print(f"Errado:  {errado}")
# Correto: SÃ£o Paulo
# Errado:  SÃƒÂ£o Paulo
# 'Ã£' em UTF-8 = [0xC3, 0xA3] â†’ Latin-1 lÃª como 'Ãƒ' (0xC3) + 'Â£' (0xA3)


# --- Code points Unicode ---

# ord() retorna o code point de um caractere
# chr() retorna o caractere de um code point
print(f"'A' = U+{ord('A'):04X}")    # U+0041
print(f"'Ã©' = U+{ord('Ã©'):04X}")    # U+00E9
print(f"'Ã£' = U+{ord('Ã£'):04X}")    # U+00E3
print(f"'â‚¬' = U+{ord('â‚¬'):04X}")    # U+20AC
print(f"'ğŸ˜€' = U+{ord('ğŸ˜€'):04X}")  # U+1F600

print(chr(0x00E9))  # 'Ã©'
print(chr(0x1F600)) # 'ğŸ˜€'

# Escape Unicode em strings
print("\u00e9")      # 'Ã©' â€” escape de 4 dÃ­gitos (BMP)
print("\U0001F600")  # 'ğŸ˜€' â€” escape de 8 dÃ­gitos (supplementary)


# --- Emojis e grafemas ---

# len() conta code points, nÃ£o grafemas visuais
print(len("ğŸ˜€"))          # 1 â€” emoji simples = 1 code point
print(len("ğŸ‡§ğŸ‡·"))        # 2 â€” bandeira = 2 regional indicators
print(len("ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦"))  # 7 â€” famÃ­lia = 4 emojis + 3 ZWJ (zero-width joiners)

# Para contar grafemas visuais, usar biblioteca (ex: grapheme)
# ou regex com \X (grapheme cluster)


# --- Ler arquivo com encoding especÃ­fico ---

# Especificar encoding Ã© essencial para evitar mojibake em arquivos
with open("dados.csv", "r", encoding="utf-8") as f:
    conteudo = f.read()

# Para arquivos legados em Latin-1:
# with open("legado.csv", "r", encoding="latin-1") as f:
#     conteudo = f.read()

# errors="replace" substitui bytes invÃ¡lidos por 'ï¿½' ao invÃ©s de crashear
# with open("misto.txt", "r", encoding="utf-8", errors="replace") as f:
#     conteudo = f.read()


# --- Detectar encoding (quando desconhecido) ---

# A stdlib nÃ£o detecta automaticamente â€” usar chardet ou charset-normalizer
# pip install charset-normalizer

# from charset_normalizer import from_bytes
# resultado = from_bytes(bytes_desconhecidos)
# encoding_detectado = resultado.best().encoding
# texto = str(resultado.best())
